{"backend_state":"ready","kernel":"jasondumb","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"trust":false,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"59d4ed","input":"#####################\n# Generating output #\n#####################","pos":9,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":1,"id":"196761","input":"###########\n# Imports #\n###########\n\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nfrom aitextgen import aitextgen","output":{"0":{"name":"stderr","output_type":"stream","text":"2022-06-23 16:04:59.106943: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"}},"pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":123,"id":"fdbbc9","input":"# Nicki Minaj Generate\nlist = nk_ai.generate(n=1, \n               batch_size=5, \n               prompt=\"Raj\", \n               max_length=100, \n               temperature=1, \n               top_p=3,\n               return_as_list=True)\n\nprint(list)\nprint('================================')\nfix_grammar(list[0])","output":{"0":{"name":"stdout","output_type":"stream","text":"\u001b[1mRaj\u001b[0m is who you ain't fu..in' with\n\n==========\n\u001b[1mRaj\u001b[0m. What shes delivering to the world now is basically what they want. But I know that shes a super talented superstar who can do anything at a high levelrap, sing, act, whatever she wants to do. This is just the beginning of Nicki Minaj. Her best is yet to come. In my opinion she is as talented as my other girl Lauryn Hill. They have completely different styles. But as far as the talent is concerned they both can do\n==========\n\u001b[1mRaj\u001b[0m a show for Versace, they request me by name and if they don't get Nicki, it just won't be the same.\n\n==========\n\u001b[1mRaj\u001b[0m? Now lets get nasty.\n\n==========\n\u001b[1mRaj\u001b[0m is who you ain't fu..in' with\n\n"}},"pos":12,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":131,"id":"5128e4","input":"##################\n# Load the model #\n##################\n\nsp_ai = aitextgen(model_folder=\"model/sp_ai\")\nnk_ai = aitextgen(model_folder=\"model/nk_ai\")\ndt_ai = aitextgen(model_folder=\"model/dt_ai\")\ngr_ai = aitextgen(model_folder=\"model/gr_ai\")","pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":134,"id":"17c97c","input":"# Gordon Ramsey Generate\ngr_ai.generate(n=5, \n               batch_size=5, \n               prompt=\"Andre G\", \n               min_length=10,\n               max_length=100, \n               temperature=1, \n               top_p=2)","output":{"0":{"name":"stdout","output_type":"stream","text":"\u001b[1mAndre G\u001b[0m.S.\nre all self-obsessed, delicate, dainty, insecure little souls, and absolute psychopaths. Every last one of them.\n\n==========\n\u001b[1mAndre G\u001b[0m.\nI’m Gordon Ramsay, for goodness sake; people know I’m volatile.\n\n==========\n\u001b[1mAndre G\u001b[0m.S.\n\n\n are nutters.\n\n==========\n\u001b[1mAndre G\u001b[0m.\n—. And she’s dead!\n\n==========\n\u001b[1mAndre G\u001b[0mata.'\n—.\nakuna Matata.'\n\n"}},"pos":14,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":137,"id":"1cba80","input":"# Donald Trump Generate\nlist = dt_ai.generate(n=5, \n               batch_size=5,\n               prompt=\"Groot\",\n               min_length=10,\n               max_length=100,\n               temperature=1,\n               top_p=1.5,\n               return_as_list=True)\nfor l in list:\n    fix_grammar(l)","output":{"0":{"name":"stdout","output_type":"stream","text":"Groot in the ballot boxes (on video), double voters, dead voters.\nGroot\n.\nGroot a new voter fraud.\nGroot no information about the sample.\nGroot commission.\n"}},"pos":13,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":145,"id":"2ab640","input":"# Shakespeare Generate\nsp_ai.generate(n=5, \n              batch_size=5, \n              prompt=\"Jun\", \n              min_length=10, \n              max_length=100, \n              temperature=1, \n              top_p=0.9)","output":{"0":{"name":"stdout","output_type":"stream","text":"\u001b[1mJun\u001b[0m face is not worth sunburning.\n\n==========\n\u001b[1mJun\u001b[0m, and proud coward, an hourly promise breaker, the owner of no one good quality.\n\n==========\n\u001b[1mJun\u001b[0m.\n\n\n\n\n\n\n\n==========\n\u001b[1mJun\u001b[0m face, So full of frost, of storm, and cloudiness. \n\n==========\n\u001b[1mJun\u001b[0m, I have done thy mother. \n\n"}},"pos":10,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"da0784","input":"###############################\n# Data import & Preprocessing #\n###############################\n\nsp_txt = \"Data/ShakespeareInsults.txt\"\nnj_txt = \"Data/NickiMinaj.txt\"\ndt_txt = \"Data/trump_data_with_caps_periods.txt\"\ngr_txt = \"Data/gordonramsayinsults.txt\"","pos":1,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":3,"id":"29d42d","input":"######################\n# Def Train Function #\n######################\n\nimport torch\ntorch.cuda.empty_cache()\n\ndef train_model(txt, steps, output_path):\n    model = aitextgen(tf_gpt2=\"124M\", to_gpu=True)\n    model.train(txt,\n         line_by_line=True,\n         from_cache=False,\n         num_steps=steps,\n         generate_every=500,\n         save_every=500,\n         save_gdrive=False,\n         learning_rate=1e-3,\n         fp16=False,\n         output_dir=output_path,\n         batch_size=1\n         )","pos":2,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"7a0467","input":"# Donald Trump\ndt_ai = train_model(dt_txt, 5000, 'model/dt_ai')","output":{"0":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5344100996d45f885cbc307e68df3c6","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/6449 [00:00<?, ?it/s]"},"exec_count":4,"output_type":"execute_result"},"1":{"name":"stderr","output_type":"stream","text":"pytorch_model.bin already exists in /model/dt_ai and will be overwritten!\n"},"10":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n"},"11":{"name":"stdout","output_type":"stream","text":"==========\n many dishonest reporters.fake news suppression polls.they show phony polls just like they report fake polls.never even show up to vote.worst pollsters.produced so poorly compared to the fake news media.our country can't get any worse.they make up fake stories in order to get attention.few people know that fortune magazine is still in business.considered the worst fbi director in the history of its political system.long and boring.w boring.not good!not good!not good!only makes bad deals!not good!not at stopping people from flowing into mexico through their southern border.they must stop the big drug and people flows, or i will stop their cash cow, nafta.has no effective border laws.slow walking, or even less stamina.terrible.obstruction!obstructionists!report the great (hacking) i won big, and easily won!the most inaccurate (and fraudulent) case of (1,000) in the history of american politics.never wins elections!didn't do a very poor very poor job!terrible, inaccurate and even fraudulent numbers.russian collusion with the trump campaign.get the facts straight.they don't want to report the facts.just want\n==========\n"},"12":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"13":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n==========\n\n\n==========\n"},"14":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"15":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n"},"16":{"name":"stdout","output_type":"stream","text":"==========\njust a continuation of the dnc.slanted, with the democrat party in the midterms.13 angry and conflicted democrats.the world’s most expensive witch hunt.a phony scam.i have never seen.a very bad show with their fake news.the worst of them all!a total scam on a scale not seen before.a tremendous waste of time and energy.on a new phony kick about my management style.very expensive and unpopular.flat broke and unconstitutional!18 angry democrats.will never be satisfied with anything we give them.always resist and obstructing.nothing will ever come them.the greatest hoax.trump hater.sleepy joe.a total fraud on your president and the american people!watch out for people that take so-called “notes” on your show.bad ratings,  a disgrace to our country.has become so partisan, distorted.doesn’t understand what the word demagoguery means.failed on transition.upset that they were saying when i wouldn’t be doing in their own card - now he’ll be doing poorly.doesn’t understand what the word demagoguery means.failed on transition.should be ashamed of herself\n==========\n"},"17":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"18":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n"},"19":{"name":"stdout","output_type":"stream","text":"==========\n be laughed at all over the world,a total joke,sick and bad,what the hell has happened to them.bad, in perhaps the end,made all sorts of crazy charges,can't believe how badly @cnn has done in the ratings,lyin’ james comey? take away millions of dollars a year, while charging amazon and others.must pay a big story about me.disgraceful!totally untrue.lies in congress.he is supposed to know the law.guilty on so many charges unrelated to me.they want to scare everybody into making up stories that are not true by catching them in the smallest of misstatements. sad!old, very costly & anti-usa.failed prognosticator.never had a clue.pathetic and dishonest.flat broke and out of business.rest in peace!such a big story that will never be covered by the fake news.anarchists, agitators, and looters.unstable.rightfully shunned, scorned and mocked.never liked, and mocked.never liked, quote anonymous sources (who don't got fired)such a mess.nothing works.all.a low-life who should suspend him for remainder of\n==========\n"},"2":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n  rank_zero_deprecation(\nGPU available: True, used: True\n"},"20":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"21":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n==========\n\n==========\n"},"22":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"23":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n==========\n.\n\n==========\n"},"24":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"25":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,500 steps reached: generating sample texts.\u001b[0m\n==========\n\n==========\n"},"26":{"name":"stdout","output_type":"stream","text":"\u001b[1m4,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"27":{"name":"stdout","output_type":"stream","text":"\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n"},"28":{"name":"stdout","output_type":"stream","text":"==========\ntrying to extort $1,000.00 from me.mormons don't like liars!the man who ‘choked’ and let us all down.a mixed up man who doesn't have a clue. no wonder he lost!never worth watching.the most overrated person on tv.one of the dumbest of all pundits.he has no sense of the real world!dummy!so average in so many ways!looks and sounds so ridiculous.just another dishonest politician.obsolete.all talk and no action!a ‘hell hole’.a mess.a mess.failing so badly that it will soon be taken off thr air.another phony hit job on me.totally biased.losing big.really one-sided and unfair reporting.got thrown off of tv by nbc.fired like a dog!a dumb group!in total disarray.almost everybody quitting.bad, dishonest journlists.attacked new yorkers and new york values- we don't forget!unqualified to be president.covers me so inaccurately.i win a state in votes and then get non-representative delegates because they are offered all sorts of goodies by cruz campaign\n==========\n"},"29":{"name":"stdout","output_type":"stream","text":"\u001b[1m4,500 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"3":{"name":"stderr","output_type":"stream","text":"TPU available: False, using: 0 TPU cores\n"},"30":{"name":"stdout","output_type":"stream","text":"\u001b[1m4,500 steps reached: generating sample texts.\u001b[0m\n"},"31":{"name":"stdout","output_type":"stream","text":"==========\nings are way down!should issue an apology to america!no matter what i do or say, they will not write or speak truth,out of control!low news and reporting standards,fake news networks,just made up,fighting for the violent ms-13 killer gangs & sanctuary cities,dealing with the democrats for their very unfunny & repetitive material,always anti-trump!so knowingly inaccurate with their reporting,badly broken, big premiums,one-sided coverage,disrespecting our country,‘begged’ me to endorse him for re-election,i said ‘no‘ and he dropped out,largely responsible for the horrendous iran deal!a negative voice,in the way of our great agenda,didn't have the guts to run!gave us the iran deal, & that's about it,showed such disrespect for country!with jemele hill at the mike, it is no wonder espn ratings have 'tanked,' in fact, tanked so badly it is the talk of the industry!getting massive tax breaks while at the same time disrespecting our anthem, flag and country,it is no wonder espn ratings have 'tanked,' in fact, tanked\n==========\n"},"32":{"name":"stdout","output_type":"stream","text":"\u001b[1m5,000 steps reached: saving model to /model/dt_ai\u001b[0m\n"},"33":{"name":"stdout","output_type":"stream","text":"\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n"},"34":{"name":"stdout","output_type":"stream","text":"==========\n and not for the great state of kentucky,many polls are much better,if it is fake news @washingtonpost, add 10 points!all the news that’s not fit to print,it is “hell” dealing with the dems,gretchen “half” whitmer,way in over her head,blaming everyone for her own ineptitude & ineptitude,a third rate reporter who has nothing going.a fake news “journalist”.such fake reporting.corrupt and disgusting.lamestream media  very dangerous & corrupt people, who have totally and can’t even speak up and have zero presence.a waste of time.little adam schiff.part of the crooked’s emails is corrupt.fake news media, fake news media, and all bad for our country.a total disaster.fake news media,  crazy.always seeking to make me look as bad as possible.did a bad interview.so bad for the worker of bernie sanders.lyin’ brian williams.totally fabricated a war story.a very dishonest journalist!forgot the people who got them there.watching @foxnews weekend anchors is worse than\n==========\n"},"4":{"name":"stderr","output_type":"stream","text":"IPU available: False, using: 0 IPUs\n"},"5":{"name":"stderr","output_type":"stream","text":"HPU available: False, using: 0 HPUs\n"},"6":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n  rank_zero_deprecation(\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"},"7":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d29b7d6022564b6f96654b9d5ff93113","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/5000 [00:00<?, ?it/s]"},"exec_count":4,"output_type":"execute_result"},"8":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n  rank_zero_deprecation(\n"},"9":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: saving model to /model/dt_ai\u001b[0m\n"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"87cb2b","input":"#######################\n# Training the models #\n#######################","pos":3,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"febf5c","input":"# Gordan Ramsey\ngr_ai = train_model(gr_txt, 3000, 'model/gr_ai')","output":{"0":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"409b1baf121f49ff96f316783d1e32e1","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/124 [00:00<?, ?it/s]"},"exec_count":4,"output_type":"execute_result"},"1":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n  rank_zero_deprecation(\nGPU available: True, used: True\n"},"10":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"11":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n"},"12":{"name":"stdout","output_type":"stream","text":"==========\nYou’m not critic-proof, and I still take it personally, but I take it less personally now.\n\n==========\n"},"13":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"14":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n==========\n\n==========\n"},"15":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"16":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n==========\nStop taking things personally.\n\n==========\n"},"17":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"18":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n"},"19":{"name":"stdout","output_type":"stream","text":"==========\nI’m Gordon Ramsay, for goodness sake; people know I’m volatile.\n\n==========\n"},"2":{"name":"stderr","output_type":"stream","text":"TPU available: False, using: 0 TPU cores\n"},"20":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"21":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n"},"22":{"name":"stdout","output_type":"stream","text":"==========\nYou used so much oil, the U.S. want to invade the f—ing plate.\n\n==========\n"},"3":{"name":"stderr","output_type":"stream","text":"IPU available: False, using: 0 IPUs\n"},"4":{"name":"stderr","output_type":"stream","text":"HPU available: False, using: 0 HPUs\n"},"5":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n  rank_zero_deprecation(\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"},"6":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a55065df4ce45c3b1344c965408b952","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]"},"exec_count":4,"output_type":"execute_result"},"7":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n  rank_zero_deprecation(\n"},"8":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: saving model to /model/gr_ai\u001b[0m\n"},"9":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n==========\n.\n\n==========\n"}},"pos":7,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":53,"id":"031742","input":"# trump grammar fixer (i hope)\nimport string\n\ndef fix_grammar(input):\n    end_punc = '.?!'\n    no_first_letter = True\n    fixed_grammar = ''\n    index = 0\n    for index in range(len(input)):\n        char = input[index]\n        if char not in string.ascii_letters and no_first_letter:\n            #if the first character isn't a letter, it ignores it until it finds a letter\n            continue\n        elif char in string.ascii_letters and no_first_letter:\n            #if it finds the first letter, it adds it to the edited version\n            no_first_letter = False\n            char = char.upper()w\n            fixed_grammar += (char)\n        elif char == ',' and input[index+1] != ' ':\n            #if it findas a comma with no space after it, it will add the comma and a space to the edited version\n            fixed_grammar += ', '\n        elif char == ' ' and input[index+1] == ' ':\n            #if it detects a double space it doesnt add the first space, and so on until there's only one space\n            continue\n        else:\n            fixed_grammar += (char)\n        if char in end_punc:\n            break\n\n    print(fixed_grammar)\n\nfix_grammar(', is the enemy of the people, will do anything,  they can to do to,get the ‘justice.will never get anything done.')\nfix_grammar('i’ve got to be boisterous to get results.')\nfix_grammar('Hello World')","output":{"0":{"name":"stdout","output_type":"stream","text":"Is the enemy of the people, will do anything, they can to do to, get the ‘justice.\nI’ve got to be boisterous to get results.\nHello World\n"}},"pos":11,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":6,"id":"f785ed","input":"# Shakespeare\nsp_ai = train_model(sp_txt, 3000, 'model/sp_ai')","output":{"0":{"name":"stderr","output_type":"stream","text":"2022-06-20 14:59:41.755589: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"},"1":{"name":"stderr","output_type":"stream","text":"Converting TensorFlow checkpoint from /projects/20faf27f-1124-4aa0-b984-e0c449973ff4/Project/aitextgen/124M\n"},"10":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n"},"100":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/attn/c_proj/b with shape [768]\n"},"101":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n"},"102":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/ln_1/b with shape [768]\n"},"103":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/ln_1/g with shape [768]\n"},"104":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/ln_2/b with shape [768]\n"},"105":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/ln_2/g with shape [768]\n"},"106":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n"},"107":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n"},"108":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n"},"109":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n"},"11":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n"},"110":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n"},"111":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n"},"112":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/attn/c_proj/b with shape [768]\n"},"113":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n"},"114":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/ln_1/b with shape [768]\n"},"115":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/ln_1/g with shape [768]\n"},"116":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/ln_2/b with shape [768]\n"},"117":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/ln_2/g with shape [768]\n"},"118":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n"},"119":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n"},"12":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n"},"120":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n"},"121":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n"},"122":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n"},"123":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n"},"124":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/attn/c_proj/b with shape [768]\n"},"125":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n"},"126":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/ln_1/b with shape [768]\n"},"127":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/ln_1/g with shape [768]\n"},"128":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/ln_2/b with shape [768]\n"},"129":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/ln_2/g with shape [768]\n"},"13":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n"},"130":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n"},"131":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n"},"132":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n"},"133":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n"},"134":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n"},"135":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n"},"136":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/attn/c_proj/b with shape [768]\n"},"137":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n"},"138":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/ln_1/b with shape [768]\n"},"139":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/ln_1/g with shape [768]\n"},"14":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n"},"140":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/ln_2/b with shape [768]\n"},"141":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/ln_2/g with shape [768]\n"},"142":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n"},"143":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n"},"144":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n"},"145":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n"},"146":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/ln_f/b with shape [768]\n"},"147":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/ln_f/g with shape [768]\n"},"148":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/wpe with shape [1024, 768]\n"},"149":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/wte with shape [50257, 768]\n"},"15":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n"},"150":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n"},"151":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n"},"152":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n"},"153":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n"},"154":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'ln_1', 'b']\n"},"155":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'ln_1', 'g']\n"},"156":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'ln_2', 'b']\n"},"157":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'ln_2', 'g']\n"},"158":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n"},"159":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n"},"16":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/attn/c_proj/b with shape [768]\n"},"160":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n"},"161":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n"},"162":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n"},"163":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n"},"164":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n"},"165":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n"},"166":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'ln_1', 'b']\n"},"167":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'ln_1', 'g']\n"},"168":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'ln_2', 'b']\n"},"169":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'ln_2', 'g']\n"},"17":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n"},"170":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n"},"171":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n"},"172":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n"},"173":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n"},"174":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n"},"175":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n"},"176":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n"},"177":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n"},"178":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'ln_1', 'b']\n"},"179":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'ln_1', 'g']\n"},"18":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/ln_1/b with shape [768]\n"},"180":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'ln_2', 'b']\n"},"181":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'ln_2', 'g']\n"},"182":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n"},"183":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n"},"184":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n"},"185":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n"},"186":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n"},"187":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n"},"188":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n"},"189":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n"},"19":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/ln_1/g with shape [768]\n"},"190":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'ln_1', 'b']\n"},"191":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'ln_1', 'g']\n"},"192":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'ln_2', 'b']\n"},"193":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'ln_2', 'g']\n"},"194":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n"},"195":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n"},"196":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n"},"197":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n"},"198":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n"},"199":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n"},"2":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n"},"20":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/ln_2/b with shape [768]\n"},"200":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n"},"201":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n"},"202":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'ln_1', 'b']\n"},"203":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'ln_1', 'g']\n"},"204":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'ln_2', 'b']\n"},"205":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'ln_2', 'g']\n"},"206":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n"},"207":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n"},"208":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n"},"209":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n"},"21":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/ln_2/g with shape [768]\n"},"210":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n"},"211":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n"},"212":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n"},"213":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n"},"214":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'ln_1', 'b']\n"},"215":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'ln_1', 'g']\n"},"216":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'ln_2', 'b']\n"},"217":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'ln_2', 'g']\n"},"218":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n"},"219":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n"},"22":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n"},"220":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n"},"221":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n"},"222":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n"},"223":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n"},"224":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n"},"225":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n"},"226":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'ln_1', 'b']\n"},"227":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'ln_1', 'g']\n"},"228":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'ln_2', 'b']\n"},"229":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'ln_2', 'g']\n"},"23":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n"},"230":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n"},"231":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n"},"232":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n"},"233":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n"},"234":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n"},"235":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n"},"236":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n"},"237":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n"},"238":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'ln_1', 'b']\n"},"239":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'ln_1', 'g']\n"},"24":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n"},"240":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'ln_2', 'b']\n"},"241":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'ln_2', 'g']\n"},"242":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n"},"243":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n"},"244":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n"},"245":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n"},"246":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n"},"247":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n"},"248":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n"},"249":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n"},"25":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n"},"250":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'ln_1', 'b']\n"},"251":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'ln_1', 'g']\n"},"252":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'ln_2', 'b']\n"},"253":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'ln_2', 'g']\n"},"254":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n"},"255":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n"},"256":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n"},"257":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n"},"258":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n"},"259":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n"},"26":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n"},"260":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n"},"261":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n"},"262":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'ln_1', 'b']\n"},"263":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'ln_1', 'g']\n"},"264":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'ln_2', 'b']\n"},"265":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'ln_2', 'g']\n"},"266":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n"},"267":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n"},"268":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n"},"269":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n"},"27":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n"},"270":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n"},"271":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n"},"272":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n"},"273":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n"},"274":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'ln_1', 'b']\n"},"275":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'ln_1', 'g']\n"},"276":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'ln_2', 'b']\n"},"277":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'ln_2', 'g']\n"},"278":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n"},"279":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n"},"28":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/attn/c_proj/b with shape [768]\n"},"280":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n"},"281":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n"},"282":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n"},"283":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n"},"284":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n"},"285":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n"},"286":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'ln_1', 'b']\n"},"287":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'ln_1', 'g']\n"},"288":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'ln_2', 'b']\n"},"289":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'ln_2', 'g']\n"},"29":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n"},"290":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n"},"291":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n"},"292":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n"},"293":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n"},"294":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['ln_f', 'b']\n"},"295":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['ln_f', 'g']\n"},"296":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['wpe']\n"},"297":{"name":"stderr","output_type":"stream","text":"Initialize PyTorch weight ['wte']\n"},"298":{"name":"stdout","output_type":"stream","text":"Save PyTorch model to aitextgen/pytorch_model.bin\n"},"299":{"name":"stdout","output_type":"stream","text":"Save configuration file to aitextgen/config.json\n"},"3":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n"},"30":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/ln_1/b with shape [768]\n"},"300":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"555c1b4f7de04a79bee7fbcecb459b8c","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/343 [00:00<?, ?it/s]"},"exec_count":6,"output_type":"execute_result"},"301":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n  rank_zero_deprecation(\n/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n  rank_zero_deprecation(\nGPU available: True, used: True\n"},"302":{"name":"stderr","output_type":"stream","text":"TPU available: False, using: 0 TPU cores\n"},"303":{"name":"stderr","output_type":"stream","text":"IPU available: False, using: 0 IPUs\n"},"304":{"name":"stderr","output_type":"stream","text":"HPU available: False, using: 0 HPUs\n"},"305":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n  rank_zero_deprecation(\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"},"306":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2afca5ac963f44f8834a6f27c15b43c3","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]"},"exec_count":6,"output_type":"execute_result"},"307":{"name":"stderr","output_type":"stream","text":"/projects/20faf27f-1124-4aa0-b984-e0c449973ff4/miniconda3/envs/jasonisdumb/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:2281: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n  rank_zero_deprecation(\n"},"308":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"309":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n==========\nThou reeky base-court vassal.\n\n==========\n"},"31":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/ln_1/g with shape [768]\n"},"310":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"311":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n==========\n\n==========\n"},"312":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"313":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n==========\nThou art the cap of all the fools. \n\n==========\n"},"314":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"315":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n==========\nThou spleeny tickle-brained coxcomb.\n\n==========\n"},"316":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"317":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n==========\nAway, you three-inch fool! \n\n==========\n"},"318":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: saving model to /model/sp_ai\u001b[0m\n"},"319":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n==========\n the tartness of his face sours ripe grapes. \n\n==========\n"},"32":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/ln_2/b with shape [768]\n"},"33":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/ln_2/g with shape [768]\n"},"34":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n"},"35":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n"},"36":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n"},"37":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n"},"38":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n"},"39":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n"},"4":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/attn/c_proj/b with shape [768]\n"},"40":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/attn/c_proj/b with shape [768]\n"},"41":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n"},"42":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/ln_1/b with shape [768]\n"},"43":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/ln_1/g with shape [768]\n"},"44":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/ln_2/b with shape [768]\n"},"45":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/ln_2/g with shape [768]\n"},"46":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n"},"47":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n"},"48":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n"},"49":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n"},"5":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n"},"50":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n"},"51":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n"},"52":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/attn/c_proj/b with shape [768]\n"},"53":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n"},"54":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/ln_1/b with shape [768]\n"},"55":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/ln_1/g with shape [768]\n"},"56":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/ln_2/b with shape [768]\n"},"57":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/ln_2/g with shape [768]\n"},"58":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n"},"59":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n"},"6":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/ln_1/b with shape [768]\n"},"60":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n"},"61":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n"},"62":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n"},"63":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n"},"64":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/attn/c_proj/b with shape [768]\n"},"65":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n"},"66":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/ln_1/b with shape [768]\n"},"67":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/ln_1/g with shape [768]\n"},"68":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/ln_2/b with shape [768]\n"},"69":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/ln_2/g with shape [768]\n"},"7":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/ln_1/g with shape [768]\n"},"70":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n"},"71":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n"},"72":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n"},"73":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n"},"74":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n"},"75":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n"},"76":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/attn/c_proj/b with shape [768]\n"},"77":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n"},"78":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/ln_1/b with shape [768]\n"},"79":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/ln_1/g with shape [768]\n"},"8":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/ln_2/b with shape [768]\n"},"80":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/ln_2/b with shape [768]\n"},"81":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/ln_2/g with shape [768]\n"},"82":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n"},"83":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n"},"84":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n"},"85":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n"},"86":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n"},"87":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n"},"88":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/attn/c_proj/b with shape [768]\n"},"89":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n"},"9":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h0/ln_2/g with shape [768]\n"},"90":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/ln_1/b with shape [768]\n"},"91":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/ln_1/g with shape [768]\n"},"92":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/ln_2/b with shape [768]\n"},"93":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/ln_2/g with shape [768]\n"},"94":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n"},"95":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n"},"96":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n"},"97":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n"},"98":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n"},"99":{"name":"stderr","output_type":"stream","text":"Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n"}},"pos":4,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"6bba08","input":"# Nicki Minaj\nnk_ai = train_model(nj_txt, 3000, 'model/nk_ai')","output":{"0":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ec2ccce70914c12943b5fc3967d6222","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/61 [00:00<?, ?it/s]"},"exec_count":7,"output_type":"execute_result"},"1":{"name":"stderr","output_type":"stream","text":"GPU available: True, used: True\n"},"10":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n"},"11":{"name":"stdout","output_type":"stream","text":"==========\nEverybody gon' see where I'm lyrically at; used to hate Nicki, now they givin me dap.\n\n==========\n"},"12":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: saving model to /model/nk_ai\u001b[0m\n"},"13":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,500 steps reached: generating sample texts.\u001b[0m\n"},"14":{"name":"stdout","output_type":"stream","text":"==========\nYou bad, but Nicki is badder Step ya cookies up, go get you a ladder.\n\n==========\n"},"15":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"},"16":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n"},"17":{"name":"stdout","output_type":"stream","text":"==========\nWhite girls tell me hey, Nicki your camp rules. Is that why you get more head than shampoos.\n\n==========\n"},"18":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: saving model to /model/nk_ai\u001b[0m\n"},"19":{"name":"stdout","output_type":"stream","text":"\u001b[1m2,500 steps reached: generating sample texts.\u001b[0m\n"},"2":{"name":"stderr","output_type":"stream","text":"TPU available: False, using: 0 TPU cores\n"},"20":{"name":"stdout","output_type":"stream","text":"==========\nWhite girls tell me hey, Nicki your camp rules. Is that why you get more head than shampoos.\n\n==========\n"},"21":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"},"22":{"name":"stdout","output_type":"stream","text":"\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n"},"23":{"name":"stdout","output_type":"stream","text":"==========\nForget barbie, fu.. Nicki, she's fake. She's on a diet but my pockets eating cheesecake.\n\n==========\n"},"3":{"name":"stderr","output_type":"stream","text":"IPU available: False, using: 0 IPUs\n"},"4":{"name":"stderr","output_type":"stream","text":"HPU available: False, using: 0 HPUs\n"},"5":{"name":"stderr","output_type":"stream","text":"LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"},"6":{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"64a1f92623244fb0955c4b7d5b345b47","version_major":2,"version_minor":0},"text/plain":"  0%|          | 0/3000 [00:00<?, ?it/s]"},"exec_count":7,"output_type":"execute_result"},"7":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: saving model to /model/nk_ai\u001b[0m\n"},"8":{"name":"stdout","output_type":"stream","text":"\u001b[1m500 steps reached: generating sample texts.\u001b[0m\n==========\n, I'm finicky, I'm picky.\n\n==========\n"},"9":{"name":"stdout","output_type":"stream","text":"\u001b[1m1,000 steps reached: saving model to /model/nk_ai\u001b[0m\n"}},"pos":5,"scrolled":true,"state":"done","type":"cell"}
{"id":0,"time":1656034297483,"type":"user"}
{"last_load":1656034297040,"type":"file"}